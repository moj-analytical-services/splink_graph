name: continuous-integration-workflow.yml

on:  [push,pull_request]  
jobs:
  preview:
    name: Test splinkgraph
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.8']
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 1
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}
      - uses: actions/setup-java@v2
        with:
          distribution: "zulu"
          java-version: "8"
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest wheel pytest-order
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install "git+https://github.com/mamonu/graphframes.git@master#egg=graphframes&subdirectory=python"
      - name: Setup Spark
        env:
          SPARK_VERSION: 3.1.1
          HADOOP_VERSION: 3.2
        run: |
          wget https://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz
          tar -xzf spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz -C $HOME
          rm spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION.tgz
          ln -s $HOME/spark-$SPARK_VERSION-bin-hadoop$HADOOP_VERSION $HOME/spark
          export SPARK_HOME=$HOME/spark 
          echo SPARK_HOME=$SPARK_HOME >> $GITHUB_ENV
          echo $SPARK_HOME/bin >> $GITHUB_PATH
      - name: Run tests with pytest
        run: |
          pytest -vv
